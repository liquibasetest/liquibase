WITH json_data AS (
  SELECT 
    table_name,
    OBJECT_AGG('column_name', column_name, 'group_name', group_name) AS column_data
  FROM table_metadata
  GROUP BY table_name, column_name, group_name
)
SELECT 
  table_name,
  OBJECT_CONSTRUCT('columns', ARRAY_AGG(column_data)) AS table_json
FROM json_data
GROUP BY table_name;


In Snowflake, creating a storage integration with Amazon S3 involves setting up a secure connection between Snowflake and an S3 bucket. The process includes:

Creating an IAM Role in AWS: This role grants Snowflake permissions to access the S3 bucket, with specific policies for reading and writing data.
Setting Up the Storage Integration in Snowflake: This involves defining the integration, specifying the IAM role ARN, and allowing access to the S3 bucket.
Updating the IAM Role's Trust Policy: Adding Snowflake's external ID to the IAM role's trust relationship ensures secure access.


Given that the majority of our compute will take place in the ABC Snowflake account, and the ABC team has already estimated the costs for that account, the usage in the AT Snowflake account is expected to be minimal. Additionally, it is uncertain whether other projects will utilize Snowflake. Therefore, I've provided an estimation for minimal credits for the year. I also inquired about the inclusion of 2024 in the budget, and even Ariel is uncertain about it. Thus, I'll share this estimation for now

For the Proof of Concept (POC), the key objective is to demonstrate the performance improvement and cost-efficiency of transitioning from using S3 Parquet files as external tables in Snowflake to using the Apache Iceberg format. The current approach has cost advantages but suffers from performance issues when querying non-partitioned fields. By converting S3 Parquet files to Iceberg format and accessing them as unmanaged Iceberg tables in Snowflake, we aim to enhance query performance while maintaining or reducing costs.

Key Objective for the POC
Current Approach
External Tables in Snowflake: Parquet files stored in S3 are currently projected as external tables in Snowflake.
Cost Efficiency: This approach reduces storage costs because data is stored in S3 and not within Snowflake.
Performance Issues: Querying non-partitioned fields results in suboptimal performance, as the current setup does not leverage advanced partitioning or indexing mechanisms.
Proposed Solution
Iceberg Format Adoption: Convert the existing S3 Parquet files into the Iceberg format, which supports features like hidden partitioning, schema evolution, and efficient query planning.
Unmanaged Iceberg Tables: Integrate these Iceberg files into Snowflake as unmanaged tables. Unmanaged tables mean that the data files remain in S3, but Iceberg handles metadata and schema evolution.
Performance Optimization: The Iceberg format allows for more efficient querying, particularly on non-partitioned fields, due to its advanced indexing and partitioning strategies.
Benefits and Goals
Improved Query Performance:

Partitioning and Indexing: Iceberg's hidden partitioning can optimize query performance on non-partitioned fields by reducing the amount of data scanned.
Metadata Caching: Improved metadata management can speed up query planning and execution.
Cost Efficiency:

Storage Costs: By continuing to store data in S3, the solution maintains the cost benefits of using external storage.
Compute Costs: Reduced query times can lower the overall compute costs in Snowflake.
Scalability and Flexibility:

Schema Evolution: Iceberg supports seamless schema changes without the need for costly and time-consuming migrations.
Data Lineage and Time Travel: Icebergâ€™s built-in capabilities for data versioning and time travel enhance data governance and auditing capabilities.
Future-Proofing:

Compatibility with Various Tools: Iceberg's open-source nature and broad support across various data processing engines ensure long-term compatibility and flexibility.
POC Implementation Plan
Data Conversion:

Convert a subset of S3 Parquet files to the Iceberg format.
Verify data integrity and consistency post-conversion.
Metadata Management:

Set up Iceberg catalogs to manage metadata and schemas.
Integrate with Snowflake as unmanaged Iceberg tables.
Performance Testing:

Conduct benchmark tests comparing query performance between the current Parquet-based setup and the new Iceberg-based setup.
Focus on queries involving non-partitioned fields and complex analytical operations.
Cost Analysis:

Compare the storage and compute costs before and after the implementation.
Project potential cost savings and performance gains at scale.
Documentation and Reporting:

Document the setup process, configurations, and performance results.
Prepare a detailed report highlighting the benefits, challenges, and recommendations based on the POC findings.
