        # Split the table into smaller chunks
        num_rows = table.num_rows
        rows_per_file = num_rows // files_per_partition
        chunks = [table[i:i+rows_per_file] for i in range(0, num_rows, rows_per_file)]
        
        # Write each chunk as a separate Parquet file
        for i, chunk in enumerate(chunks):
            file_name = f'part{i+1}.parquet'
            file_path_with_name = f'{file_path}/{file_name}'
            with s3.open(file_path_with_name, 'wb') as f:
                pq.write_table(chunk, f, compression='snappy')
