# Install necessary packages
!pip install langchain==0.1.13
!pip install openai==1.14.2
!pip install langchain-openai==0.1.0
!pip install huggingface-hub==0.21.4

# Set up OpenAI API key
import os
os.environ["OPENAI_API_KEY"] = "sk-PLfFwP2352352352hdfhdfhdhKQm3523vXr2dL8hVowXdt"

# Import necessary libraries
from langchain_openai import OpenAI
from langchain.llms import HuggingFaceEndpoint

# Create OpenAI language model object
llm = OpenAI(model_name="gpt-3.5-turbo-instruct")

# Define a query
our_query = "What is the currency of India?"

# Generate a response using the OpenAI model
completion = llm.invoke(our_query)
print(completion)

# Set up Hugging Face API token
os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_IuiVdfh546464564wrdgdfgdgfdPJaIlkYU"

# Create Hugging Face language model object
llm = HuggingFaceEndpoint(repo_id="mistralai/Mistral-7B-Instruct-v0.2")

# Generate a response using the Hugging Face model
completion = llm.invoke(our_query)
print(completion)


---------------------------------------------------------------------------------------------

#Hello! It seems like you want to import the Streamlit library in Python. Streamlit is a powerful open-source framework used for building web applications with interactive data visualizations and machine learning models. To import Streamlit, you'll need to ensure that you have it installed in your Python environment.
#Once you have Streamlit installed, you can import it into your Python script using the import statement,

import streamlit as st

#As Langchain team has been working aggresively on improving the tool, we can see a lot of changes happening every weeek,
#As a part of it, the below import has been depreciated
#from langchain.llms import OpenAI

#New import from langchain, which replaces the above
from langchain_openai import OpenAI

#When deployed on huggingface spaces, this values has to be passed using Variables & Secrets setting, as shown in the video :)
#import os
#os.environ["OPENAI_API_KEY"] = "sk-PLfFwPq6y24234234234FJ1Uc234234L8hVowXdt"

#Function to return the response
def load_answer(question):
    # "text-davinci-003" model is depreciated, so using the latest one https://platform.openai.com/docs/deprecations
    llm = OpenAI(model_name="gpt-3.5-turbo-instruct",temperature=0)

    #Last week langchain has recommended to use invoke function for the below please :)
    answer=llm.invoke(question)
    return answer


#App UI starts here
st.set_page_config(page_title="LangChain Demo", page_icon=":robot:")
st.header("LangChain Demo")

#Gets the user input
def get_text():
    input_text = st.text_input("You: ", key="input")
    return input_text


user_input=get_text()
response = load_answer(user_input)

submit = st.button('Generate')  

#If generate button is clicked
if submit:

    st.subheader("Answer:")

    st.write(response)

