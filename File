import sys
from awsglue.context import GlueContext
from pyspark.context import SparkContext
from pyspark.sql import SparkSession

# Initialize SparkContext, GlueContext, and SparkSession
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session

try:
    # Read Parquet file into a DataFrame
    parquet_file_path = "s3://your-bucket/path/to/parquet-file/"
    df = spark.read.parquet(parquet_file_path)

    # Extract partition values (partition_date and context_key_id)
    partition_values = df.select('partition_date', 'context_key_id').distinct().collect()

    # Construct partition columns string based on extracted values
    partition_columns_str = ', '.join([f"{value['partition_date']} DATE, {value['context_key_id']} STRING" for value in partition_values])

    # Specify the S3 location for the Iceberg table
    iceberg_location = 's3://your-bucket/path/to/iceberg-table/'

    # Execute SQL command to create an Iceberg table with partitioning
    spark.sql(f"""
        CREATE TABLE IF NOT EXISTS glue_db.NewIcebergTable
        USING iceberg
        PARTITIONED BY ({partition_columns_str})
        LOCATION '{iceberg_location}'
    """)

    print("Iceberg table created successfully!")
except Exception as e:
    print("Error:", e)
    sys.exit(1)
